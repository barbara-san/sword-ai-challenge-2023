{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_KEY = \"4f8e9d40be39474c96fa1327dbd47516\"\n",
    "AZURE_OPENAI_ENDPOINT = \"https://openai-resource-team-3-france.openai.azure.com/\"\n",
    "OPENAI_API_VERSION = \"2023-03-15-preview\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = AZURE_OPENAI_KEY\n",
    "os.environ[\"OPENAI_API_BASE\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_VERSION\"] = OPENAI_API_VERSION\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, I do not have personal beliefs or emotions, but here are some tips that might help you to be happy:\n",
      "\n",
      "1. Cultivate gratitude: Appreciate what you have and focus on the positives in your life.\n",
      "\n",
      "2. Practice mindfulness: Be present and fully engaged in the moment. Don't worry about the past or future.\n",
      "\n",
      "3. Connect with others: Surround yourself with positive people and cultivate meaningful relationships.\n",
      "\n",
      "4. Pursue your passions: Find activities that bring you joy and pursue them regularly.\n",
      "\n",
      "5. Take care of your physical health: Exercise regularly, eat well, and get enough sleep.\n",
      "\n",
      "6. Learn to manage stress: Develop coping strategies for dealing with stressful situations.\n",
      "\n",
      "7. Give back: Volunteer or do something kind for others.\n",
      "\n",
      "8. Practice forgiveness: Let go of grudges and resentments.\n",
      "\n",
      "Remember that happiness is a journey, not a destination. It takes effort and practice, but with the right mindset and approach, it is possible to cultivate happiness.\n"
     ]
    }
   ],
   "source": [
    "chatgpt = AzureChatOpenAI(deployment_name=\"gpt35-team-3-0301\")\n",
    "text = \"How to be happy?\"\n",
    "print(chatgpt([HumanMessage(content=text)]).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory, CombinedMemory, ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history_lines\",\n",
    "    input_key=\"input\",\n",
    "    k=1\n",
    ")\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(llm=chatgpt, input_key=\"input\")\n",
    "# Combined\n",
    "memory = CombinedMemory(memories=[conv_memory, summary_memory])\n",
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Summary of conversation:\n",
    "{history}\n",
    "Current conversation:\n",
    "{chat_history_lines}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\", \"chat_history_lines\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "#llm = gpt3\n",
    "conversation = ConversationChain(\n",
    "    llm=chatgpt, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    "    prompt=PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self, llm_to_use) -> None:\n",
    "        conv_memory = ConversationBufferWindowMemory(\n",
    "            memory_key=\"chat_history_lines\",\n",
    "            input_key=\"input\",\n",
    "            k=1\n",
    "        )\n",
    "\n",
    "        summary_memory = ConversationSummaryMemory(llm=llm_to_use, input_key=\"input\")\n",
    "        # Combined\n",
    "        memory = CombinedMemory(memories=[conv_memory, summary_memory])\n",
    "        _DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "        Summary of conversation:\n",
    "        {history}\n",
    "        Current conversation:\n",
    "        {chat_history_lines}\n",
    "        Human: {input}\n",
    "        AI:\"\"\"\n",
    "        PROMPT = PromptTemplate(\n",
    "            input_variables=[\"history\", \"input\", \"chat_history_lines\"], template=_DEFAULT_TEMPLATE\n",
    "        )\n",
    "        #llm = gpt3\n",
    "        self.conversation = ConversationChain(\n",
    "            llm=llm_to_use, \n",
    "            verbose=True, \n",
    "            memory=memory,\n",
    "            prompt=PROMPT\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "The human asks the AI what 2+2 is. The AI responds that it is 4, and explains the concept of addition involving combining two or more numbers to find their total sum.\n",
      "Current conversation:\n",
      "Human: what is 2+2?\n",
      "AI: The answer to 2+2 is 4. It is a basic arithmetic question that is commonly taught in elementary schools. The concept of addition involves combining two or more numbers to find their total sum. In this case, we are adding two numbers that are both equal to 2, so the answer is 4.\n",
      "Human: what is 2+2?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As I mentioned earlier, the answer to 2+2 is 4.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"what is 2+2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "The AI correctly answers that 2+2 is 4 and offers to show the human how it arrived at that answer.\n",
      "Current conversation:\n",
      "Human: what is 2+2?\n",
      "AI: The answer is 4. Would you like me to show you how I arrived at that answer?\n",
      "Human: What was this conversation about?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This conversation was about the question you asked me, \"what is 2+2?\" and my response that the answer is 4.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"What was this conversation about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "The AI correctly answers that 2+2 is 4 and offers to show the human how it arrived at that answer. The human asks what the conversation was about and the AI explains that it was about the question of 2+2 and its answer being 4.\n",
      "Current conversation:\n",
      "Human: What was this conversation about?\n",
      "AI: This conversation was about the question you asked me, \"what is 2+2?\" and my response that the answer is 4.\n",
      "Human: Tell me a joke about this conversation topic\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have any jokes about 2+2 equaling 4. Would you like me to tell you a different joke instead?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Tell me a joke about this conversation topic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
