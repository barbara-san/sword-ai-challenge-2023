{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_KEY = \"4f8e9d40be39474c96fa1327dbd47516\"\n",
    "AZURE_OPENAI_ENDPOINT = \"https://openai-resource-team-3-france.openai.azure.com/\"\n",
    "OPENAI_API_VERSION = \"2023-03-15-preview\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = AZURE_OPENAI_KEY\n",
    "os.environ[\"OPENAI_API_BASE\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_VERSION\"] = OPENAI_API_VERSION\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_llm = AzureChatOpenAI(deployment_name=\"gpt35-team-3-0301\", max_tokens=100)\n",
    "summary_llm = AzureChatOpenAI(deployment_name=\"gpt35-team-3-0301\")\n",
    "# text = \"How to be happy?\"\n",
    "# print(chatgpt([HumanMessage(content=text)]).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory, CombinedMemory, ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history_lines\",\n",
    "    input_key=\"input\",\n",
    "    k=1\n",
    ")\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(llm=summary_llm, input_key=\"input\")\n",
    "# Combined\n",
    "memory = CombinedMemory(memories=[conv_memory, summary_memory])\n",
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Summary of conversation:\n",
    "{history}\n",
    "Current conversation:\n",
    "{chat_history_lines}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\", \"chat_history_lines\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=math_llm, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    "    prompt=PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: what is 2+2?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to 2+2 is 4. It is a basic arithmetic problem that involves adding two numbers together. In this case, we are adding the numbers 2 and 2, which results in a total of 4.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"what is 2+2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "The human asks the AI to solve a basic arithmetic problem, specifically what is 2+2. The AI responds that the answer is 4, explaining that it involves adding two numbers together.\n",
      "Current conversation:\n",
      "Human: what is 2+2?\n",
      "AI: The answer to 2+2 is 4. It is a basic arithmetic problem that involves adding two numbers together. In this case, we are adding the numbers 2 and 2, which results in a total of 4.\n",
      "Human: No. What was this conversation about?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This conversation was about solving a basic arithmetic problem, specifically what is 2+2.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"No. What was this conversation about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "The human asks the AI to solve a basic arithmetic problem, specifically what is 2+2. The AI responds that the answer is 4, explaining that it involves adding two numbers together. The human then asks what the conversation was about, and the AI clarifies that it was about solving the arithmetic problem.\n",
      "Current conversation:\n",
      "Human: No. What was this conversation about?\n",
      "AI: This conversation was about solving a basic arithmetic problem, specifically what is 2+2.\n",
      "Human: No. Tell me a joke about the subject that the topic of this conversation fits in.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have a joke about arithmetic problems. Would you like me to search for one?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"No. Tell me a joke about the subject that the topic of this conversation fits in.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "The human asks the AI to solve a basic arithmetic problem, to which the AI responds that the answer is 4. The human then asks for a joke related to the topic of arithmetic problems, but the AI doesn't have one and offers to search for one.\n",
      "Current conversation:\n",
      "Human: No. Tell me a joke about the subject that the topic of this conversation fits in.\n",
      "AI: I'm sorry, I don't have a joke about arithmetic problems. Would you like me to search for one?\n",
      "Human: Yes, please!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, I have found a joke about arithmetic problems. Why did the math book look sad? Because it had too many problems.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Yes, please!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
